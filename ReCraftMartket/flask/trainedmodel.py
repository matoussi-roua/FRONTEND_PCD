# -*- coding: utf-8 -*-
"""4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wVgJq3ZI11YKyaQlzKeOxEdVs0utepwo
"""

import pandas as pd
import random
import numpy as np

df = pd.read_csv('C:\Users\rouam\Desktop\pcd\PCD2ndYear\ReCraftMartket\flask\alldatawithlabels')

df.drop(columns='DiscountFromOriginal', inplace=True)

df.columns = ['userId','liked', 'price', 'commented', 'shopPoints', 'state', 'wishlist','postId', 'interactionScore']

# Example: If 'commented' is greater than 3 and 'liked' is 1, set 'commented' to 1, otherwise 0
df['commented'] = df.apply(lambda row: 0 if row['commented'] < 2 or row['liked'] == 0 else 1, axis=1)

#put on the wishlist or not
df['wishlist'] = df['wishlist'].apply(lambda x: 0 if x == 2 else 1)

## state (1 for sale or 0 sold)--------------------------------------------------------------------------


# Define a function to determine the state based on the price
def determine_state(price):
    if price == -1:
        return -1  # No price (-1)
    else:
        return random.randint(0, 1)  # Random state (0 or 1)

# Apply the determine_state function to each element in the 'price' column
df['state'] = df['price'].apply(determine_state)

## post ids-------------------------------------------------------------------------------------------

# Assign unique postId values for each userId
unique_user_ids = df['userId'].unique()
max_post_id = 500  # Maximum postId value
min_post_id = 1    # Minimum postId value

# Initialize a dictionary to store postId values for each userId
user_post_ids = {}

# Iterate over unique userIds and assign unique postId values
for user_id in unique_user_ids:
    # Generate a unique range of postId values for each user
    user_post_ids[user_id] = np.arange(min_post_id, max_post_id + 1)

# Iterate over the DataFrame and assign unique postId values based on userId
post_ids = []
for user_id in df['userId']:
    # Get the postId values for the current user
    user_post_id_values = user_post_ids[user_id]

    # Pop the first postId value from the list for the current user
    post_id = user_post_id_values[0]

    # Remove the assigned postId value from the list
    user_post_ids[user_id] = user_post_id_values[1:]

    # Append the postId to the list
    post_ids.append(post_id)

# Assign the generated postId values to the DataFrame
df['postId'] = post_ids

## shop points---------------------------------------------------------------------------------

# Define a function to randomly assign shop points based on purchase history
def assign_shop_points(row, purchase_history):
    item_id = row['postId']
    state = row['state']

    if state == 1:  # Item is for sale
        if item_id in purchase_history.values():
            # Retrieve the user ID who purchased the item
            user_id = next((user_id for user_id, purchased_item_id in purchase_history.items() if purchased_item_id == item_id), None)
            if user_id == row['userId']:
                # Assign shop points to the user who purchased the item
                return 1
    # Item is sold or not purchased by the user, skip assigning shop points
    return 0

# Initialize purchase history as an empty dictionary
purchase_history = {}

# Simulate purchase history with random user IDs for each item
for item_id in range(1, 500 + 1):
    # Randomly select a user ID for each item
    user_id = random.randint(1, 200)
    purchase_history[item_id] = user_id

# Apply the function to the shopPoints column
df['shopPoints'] = df.apply(lambda row: assign_shop_points(row, purchase_history), axis=1)



##interaction score-----------------------------------------------------------------------------------

weights = {
    'likes': 0.4,
    'comments': 0.1,
    'shop_points': 0.3,
    'wishlist': 0.2
}

# Calculate interaction strength
df['interactionScore'] =  df['liked'] * weights['likes'] + \
                          df['commented'] * weights['comments'] + \
                          df['wishlist'] * weights['wishlist'] + \
                          df['shopPoints'] * weights['shop_points']

# Export data to CSV
df[['userId', 'postId', 'interactionScore']].to_csv('user_post_interactions.csv', index=False)

# Read the CSV file back into a DataFrame
inter_df = pd.read_csv('user_post_interactions.csv')

from sklearn import model_selection as cv

#cross validation/ splitting the data
train_data, test_data = cv.train_test_split(inter_df,test_size=0.25)

#!pip install pyspark

from pyspark.sql import SparkSession
from pyspark.ml.recommendation import ALS

# Initialize SparkSession
spark = SparkSession.builder \
    .appName("Recommendation System") \
    .getOrCreate()

# Initialize and train ALS model
als = ALS(maxIter=5, regParam=0.01,
          userCol="userId", itemCol="postId", ratingCol="interactionScore",
          coldStartStrategy="drop")
# Convert Pandas DataFrame to Spark DataFrame
spark_df = spark.createDataFrame(train_data)

model = als.fit(spark_df)

# Generate recommendations
userRecs = model.recommendForAllUsers(10)  # Generate top 10 recommendations for each user

# Convert Pandas DataFrame to Spark DataFrame
spark_df = spark.createDataFrame(test_data)

# Generate predictions
predictions = model.transform(spark_df)

# Convert predictions back to Pandas DataFrame
predictions_df = predictions.toPandas()

# Add the prediction column to test_data
test_data['prediction'] = predictions_df['prediction']

from pyspark.ml.evaluation import RegressionEvaluator

# Select necessary columns for evaluation
evaluator = RegressionEvaluator(metricName="rmse", labelCol="interactionScore", predictionCol="prediction")

# Calculate RMSE
rmse = evaluator.evaluate(predictions)


print("Root Mean Squared Error (RMSE):", rmse)

# Save the trained ALS model
model_path = "C:\Users\rouam\Desktop\pcd\PCD2ndYear\ReCraftMartket\flask\trainedmodel.py"
model.save(model_path)

# Stop SparkSession
spark.stop()